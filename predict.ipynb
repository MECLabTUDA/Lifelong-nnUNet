{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "from nnunet_ext.run.run_inference import run_inference\n",
    "from nnunet_ext.run.run_evaluation import run_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = '3d_fullres'\n",
    "fold = '0'\n",
    "device = '4'\n",
    "\n",
    "trainer = 'nnUNetTrainerLWF'\n",
    "\n",
    "# Prostate\n",
    "trained_on = [79, 78, 77, 76]\n",
    "use_model = [79, 78, 77, 76]\n",
    "evaluate_on = 79\n",
    "use_heads = [76, 77] #[79, 78, 77, 76]\n",
    "\n",
    "# Hyppocampus\n",
    "#trained_on = [99, 98, 97]\n",
    "#use_model = [99, 98, 97]\n",
    "#evaluate_on = 97\n",
    "#use_head = 98  # 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Adapt checkpoint\n",
    "from nnunet_ext.scripts.update_checkpoints import modify_checkpoints\n",
    "# This is always so, repeat for the new_checkpoints iterating over env variables\n",
    "current_checkpoint_root = '/local/scratch/aranem/Lifelong-nnUNet-storage/'\n",
    "old_vars = [os.path.join(current_checkpoint_root, var_name) for var_name in ['nnUNet_raw_data_base', 'nnUNet_preprocessed', 'nnUNet_trained_models', 'nnUNet_models_evaluation']]\n",
    "new_vars = [os.environ['nnUNet_raw_data_base'], os.environ['nnUNet_preprocessed'], os.environ['RESULTS_FOLDER'], os.environ['EVALUATION_FOLDER']]\n",
    "for current_checkpoint, new_checkpoint in zip(old_vars, new_vars):\n",
    "    args = [sys.argv[0], arch, trainer, '-trained_on']\n",
    "    args += [str(x) for x in trained_on]\n",
    "    args += ['-f', fold, '-r', '-rw', current_checkpoint, new_checkpoint, '-use']\n",
    "    args += [str(x) for x in use_model]\n",
    "    sys.argv = args\n",
    "    modify_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess relevant datasets\n",
    "import nnunet.experiment_planning.nnUNet_plan_and_preprocess as exp_pp\n",
    "sys.argv = [sys.argv[0], '-t', str(evaluate_on)]\n",
    "exp_pp.main()\n",
    "sys.argv = [sys.argv[0], '-t', str(trained_on[0])]\n",
    "exp_pp.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for head in use_heads:\n",
    "    # Extract predictions\n",
    "    args = [sys.argv[0], arch, trainer, '-trained_on']\n",
    "    args += [str(x) for x in trained_on]\n",
    "    args += ['-f', fold, '-use_model']\n",
    "    args += [str(x) for x in use_model]\n",
    "    args += ['-evaluate_on', str(evaluate_on), '-d', device, '-use_head', str(head), '--enable_tta']\n",
    "    # print(args)\n",
    "    sys.argv = args\n",
    "    run_inference()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
